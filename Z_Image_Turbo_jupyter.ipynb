# ===============================
# ğŸ¨ Z-IMAGE TURBO â€“ ONE CLICK UI
# ===============================

# ---------- INSTALL ----------
%%capture
!git clone -q https://github.com/comfyanonymous/ComfyUI
%cd /content/ComfyUI
!pip install -q -r requirements.txt
!apt -y install -qq aria2

!aria2c -q -c -x 16 -s 16 -k 1M \
https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors \
-d models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors

!aria2c -q -c -x 16 -s 16 -k 1M \
https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors \
-d models/clip -o qwen_3_4b.safetensors

!aria2c -q -c -x 16 -s 16 -k 1M \
https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors \
-d models/vae -o ae.safetensors

print("âœ… Install complete")


# ---------- LOAD MODELS ----------
%cd /content/ComfyUI
import os, time, random, torch, math
import numpy as np
from PIL import Image
from nodes import NODE_CLASS_MAPPINGS

UNETLoader = NODE_CLASS_MAPPINGS["UNETLoader"]()
CLIPLoader = NODE_CLASS_MAPPINGS["CLIPLoader"]()
VAELoader = NODE_CLASS_MAPPINGS["VAELoader"]()
CLIPTextEncode = NODE_CLASS_MAPPINGS["CLIPTextEncode"]()
KSampler = NODE_CLASS_MAPPINGS["KSampler"]()
VAEDecode = NODE_CLASS_MAPPINGS["VAEDecode"]()
EmptyLatentImage = NODE_CLASS_MAPPINGS["EmptyLatentImage"]()

with torch.inference_mode():
    unet = UNETLoader.load_unet(
        "z-image-turbo-fp8-e4m3fn.safetensors",
        "fp8_e4m3fn_fast"
    )[0]
    clip = CLIPLoader.load_clip(
        "qwen_3_4b.safetensors",
        type="lumina2"
    )[0]
    vae = VAELoader.load_vae("ae.safetensors")[0]

print("âœ… Models loaded")


# ---------- GENERATE ----------
@torch.inference_mode()
def generate(
    prompt, negative,
    width, height,
    steps, cfg,
    seed, sampler, scheduler,
    denoise, batch
):
    outdir = "/content/ComfyUI/output"
    os.makedirs(outdir, exist_ok=True)

    if seed == 0:
        seed = random.randint(0, 2**64 - 1)

    pos = CLIPTextEncode.encode(clip, prompt)[0]
    neg = CLIPTextEncode.encode(clip, negative)[0]

    latent = EmptyLatentImage.generate(
        width, height, batch_size=batch
    )[0]

    samples = KSampler.sample(
        unet, seed, steps, cfg,
        sampler, scheduler,
        pos, neg, latent,
        denoise=denoise
    )[0]

    decoded = VAEDecode.decode(vae, samples)[0]
    paths = []

    for i in range(batch):
        img = Image.fromarray(
            (decoded[i].cpu().numpy() * 255).astype("uint8")
        )
        p = f"{outdir}/zimage_{seed}_{i}.png"
        img.save(p)
        paths.append(p)

    return paths, seed


def make_grid(images, cols):
    rows = math.ceil(len(images) / cols)
    w, h = images[0].size
    grid = Image.new("RGB", (cols * w, rows * h))
    for i, img in enumerate(images):
        grid.paste(img, ((i % cols) * w, (i // cols) * h))
    return grid


# ---------- UI ----------
import ipywidgets as widgets
from IPython.display import display, clear_output

style = {'description_width': '120px'}
layout = widgets.Layout(width='650px')

prompt = widgets.Textarea(
    value="cinematic ultra realistic photo, dramatic lighting",
    description="Prompt",
    layout=widgets.Layout(width='650px', height='90px'),
    style=style
)

negative = widgets.Textarea(
    value="blurry, low quality, bad anatomy",
    description="Negative",
    layout=widgets.Layout(width='650px', height='70px'),
    style=style
)

width = widgets.IntSlider(1024, 512, 2048, 64, description="Width", layout=layout)
height = widgets.IntSlider(1024, 512, 2048, 64, description="Height", layout=layout)
steps = widgets.IntSlider(9, 1, 50, 1, description="Steps", layout=layout)
cfg = widgets.FloatSlider(1.0, 0.1, 10, 0.1, description="CFG", layout=layout)
denoise = widgets.FloatSlider(1.0, 0.1, 1.0, 0.05, description="Denoise", layout=layout)

batch = widgets.IntSlider(1, 1, 4, 1, description="Batch", layout=layout)
seed = widgets.IntText(0, description="Seed (0=rand)", layout=layout)

sampler = widgets.Dropdown(
    options=[
        "euler","euler_ancestral","heun",
        "dpm_2","dpm_2_ancestral",
        "lms","dpm_fast","dpm_adaptive"
    ],
    value="euler",
    description="Sampler",
    layout=layout
)

scheduler = widgets.Dropdown(
    options=["simple","normal","karras","exponential","sgm_uniform"],
    value="simple",
    description="Scheduler",
    layout=layout
)

quick = widgets.Checkbox(True, description="âš¡ Quick Mode")
grid_mode = widgets.Checkbox(False, description="ğŸ§© Grid Output")
grid_cols = widgets.IntSlider(2, 2, 4, 1, description="Grid Cols", layout=layout)

btn = widgets.Button(
    description="ğŸ¨ GENERATE",
    button_style="success",
    layout=widgets.Layout(width="220px", height="45px")
)

out = widgets.Output()

def run(b):
    with out:
        clear_output(wait=True)
        s = 9 if quick.value else steps.value
        c = 1.0 if quick.value else cfg.value

        paths, sd = generate(
            prompt.value,
            negative.value,
            width.value,
            height.value,
            s, c,
            seed.value,
            sampler.value,
            scheduler.value,
            denoise.value,
            batch.value
        )

        imgs = [Image.open(p) for p in paths]
        print(f"âœ… Done | Seed: {sd}")

        if grid_mode.value and len(imgs) > 1:
            display(make_grid(imgs, grid_cols.value))
        else:
            for i in imgs:
                display(i)

btn.on_click(run)

ui = widgets.VBox([
    widgets.HTML("<h2>ğŸ¨ Z-Image Turbo One-Click Generator</h2>"),
    prompt,
    negative,
    widgets.HBox([width, height]),
    widgets.HBox([steps, cfg]),
    denoise,
    batch,
    seed,
    sampler,
    scheduler,
    widgets.HBox([quick, grid_mode]),
    grid_cols,
    btn,
    out
])

display(ui)rate_btn = widgets.Button(\n",
    "    description='ğŸ¨ Generate Image',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_generate_click(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"ğŸ¨ Generating image...\")\n",
    "        try:\n",
    "            output_path, used_seed = generate(\n",
    "                positive_prompt=prompt_input.value,\n",
    "                negative_prompt=negative_input.value,\n",
    "                width=width_slider.value,\n",
    "                height=height_slider.value,\n",
    "                steps=steps_slider.value,\n",
    "                cfg=cfg_slider.value,\n",
    "                seed=seed_input.value,\n",
    "                sampler_name=sampler_dropdown.value,\n",
    "                scheduler=scheduler_dropdown.value\n",
    "            )\n",
    "            clear_output(wait=True)\n",
    "            print(f\"âœ… Image generated successfully!\\nğŸ² Seed used: {used_seed}\")\n",
    "            display(Image.open(output_path))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {str(e)}\")\n",
    "\n",
    "generate_btn.on_click(on_generate_click)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h2 style='color: #4CAF50;'>ğŸ¨ Z-Image Turbo Generator</h2>\"),\n",
    "    prompt_input,\n",
    "    negative_input,\n",
    "    widgets.HBox([width_slider, height_slider]),\n",
    "    widgets.HBox([steps_slider, cfg_slider]),\n",
    "    seed_input,\n",
    "    sampler_dropdown,\n",
    "    scheduler_dropdown,\n",
    "    generate_btn,\n",
    "    output_area\n",
    "])\n",
    "\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
