# ===============================
# ğŸ¨ Z-IMAGE TURBO â€“ ONE CLICK UI
# ===============================

# ---------- INSTALL ----------
%%capture
!git clone -q https://github.com/comfyanonymous/ComfyUI
%cd /content/ComfyUI
!pip install -q -r requirements.txt
!apt -y install -qq aria2

!aria2c -q -c -x 16 -s 16 -k 1M \
https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors \
-d models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors

!aria2c -q -c -x 16 -s 16 -k 1M \
https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors \
-d models/clip -o qwen_3_4b.safetensors

!aria2c -q -c -x 16 -s 16 -k 1M \
https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors \
-d models/vae -o ae.safetensors

print("âœ… Install complete")


# ---------- LOAD MODELS ----------
%cd /content/ComfyUI
import os, time, random, torch, math
import numpy as np
from PIL import Image
from nodes import NODE_CLASS_MAPPINGS

UNETLoader = NODE_CLASS_MAPPINGS["UNETLoader"]()
CLIPLoader = NODE_CLASS_MAPPINGS["CLIPLoader"]()
VAELoader = NODE_CLASS_MAPPINGS["VAELoader"]()
CLIPTextEncode = NODE_CLASS_MAPPINGS["CLIPTextEncode"]()
KSampler = NODE_CLASS_MAPPINGS["KSampler"]()
VAEDecode = NODE_CLASS_MAPPINGS["VAEDecode"]()
EmptyLatentImage = NODE_CLASS_MAPPINGS["EmptyLatentImage"]()

with torch.inference_mode():
    unet = UNETLoader.load_unet(
        "z-image-turbo-fp8-e4m3fn.safetensors",
        "fp8_e4m3fn_fast"
    )[0]
    clip = CLIPLoader.load_clip(
        "qwen_3_4b.safetensors",
        type="lumina2"
    )[0]
    vae = VAELoader.load_vae("ae.safetensors")[0]

print("âœ… Models loaded")


# ---------- GENERATE ----------
@torch.inference_mode()
def generate(
    prompt, negative,
    width, height,
    steps, cfg,
    seed, sampler, scheduler,
    denoise, batch
):
    outdir = "/content/ComfyUI/output"
    os.makedirs(outdir, exist_ok=True)

    if seed == 0:
        seed = random.randint(0, 2**64 - 1)

    pos = CLIPTextEncode.encode(clip, prompt)[0]
    neg = CLIPTextEncode.encode(clip, negative)[0]

    latent = EmptyLatentImage.generate(
        width, height, batch_size=batch
    )[0]

    samples = KSampler.sample(
        unet, seed, steps, cfg,
        sampler, scheduler,
        pos, neg, latent,
        denoise=denoise
    )[0]

    decoded = VAEDecode.decode(vae, samples)[0]
    paths = []

    for i in range(batch):
        img = Image.fromarray(
            (decoded[i].cpu().numpy() * 255).astype("uint8")
        )
        p = f"{outdir}/zimage_{seed}_{i}.png"
        img.save(p)
        paths.append(p)

    return paths, seed


def make_grid(images, cols):
    rows = math.ceil(len(images) / cols)
    w, h = images[0].size
    grid = Image.new("RGB", (cols * w, rows * h))
    for i, img in enumerate(images):
        grid.paste(img, ((i % cols) * w, (i // cols) * h))
    return grid


# ---------- UI ----------
import ipywidgets as widgets
from IPython.display import display, clear_output

style = {'description_width': '120px'}
layout = widgets.Layout(width='650px')

prompt = widgets.Textarea(
    value="cinematic ultra realistic photo, dramatic lighting",
    description="Prompt",
    layout=widgets.Layout(width='650px', height='90px'),
    style=style
)

negative = widgets.Textarea(
    value="blurry, low quality, bad anatomy",
    description="Negative",
    layout=widgets.Layout(width='650px', height='70px'),
    style=style
)

width = widgets.IntSlider(1024, 512, 2048, 64, description="Width", layout=layout)
height = widgets.IntSlider(1024, 512, 2048, 64, description="Height", layout=layout)
steps = widgets.IntSlider(9, 1, 50, 1, description="Steps", layout=layout)
cfg = widgets.FloatSlider(1.0, 0.1, 10, 0.1, description="CFG", layout=layout)
denoise = widgets.FloatSlider(1.0, 0.1, 1.0, 0.05, description="Denoise", layout=layout)

batch = widgets.IntSlider(1, 1, 4, 1, description="Batch", layout=layout)
seed = widgets.IntText(0, description="Seed (0=rand)", layout=layout)

sampler = widgets.Dropdown(
    options=[
        "euler","euler_ancestral","heun",
        "dpm_2","dpm_2_ancestral",
        "lms","dpm_fast","dpm_adaptive"
    ],
    value="euler",
    description="Sampler",
    layout=layout
)

scheduler = widgets.Dropdown(
    options=["simple","normal","karras","exponential","sgm_uniform"],
    value="simple",
    description="Scheduler",
    layout=layout
)

quick = widgets.Checkbox(True, description="âš¡ Quick Mode")
grid_mode = widgets.Checkbox(False, description="ğŸ§© Grid Output")
grid_cols = widgets.IntSlider(2, 2, 4, 1, description="Grid Cols", layout=layout)

btn = widgets.Button(
    description="ğŸ¨ GENERATE",
    button_style="success",
    layout=widgets.Layout(width="220px", height="45px")
)

out = widgets.Output()

def run(b):
    with out:
        clear_output(wait=True)
        s = 9 if quick.value else steps.value
        c = 1.0 if quick.value else cfg.value

        paths, sd = generate(
            prompt.value,
            negative.value,
            width.value,
            height.value,
            s, c,
            seed.value,
            sampler.value,
            scheduler.value,
            denoise.value,
            batch.value
        )

        imgs = [Image.open(p) for p in paths]
        print(f"âœ… Done | Seed: {sd}")

        if grid_mode.value and len(imgs) > 1:
            display(make_grid(imgs, grid_cols.value))
        else:
            for i in imgs:
                display(i)

btn.on_click(run)

ui = widgets.VBox([
    widgets.HTML("<h2>ğŸ¨ Z-Image Turbo One-Click Generator</h2>"),
    prompt,
    negative,
    widgets.HBox([width, height]),
    widgets.HBox([steps, cfg]),
    denoise,
    batch,
    seed,
    sampler,
    scheduler,
    widgets.HBox([quick, grid_mode]),
    grid_cols,
    btn,
    out
])

display(ui)    "import numpy as np\n",
    "from PIL import Image\n",
    "from nodes import NODE_CLASS_MAPPINGS\n",
    "\n",
    "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
    "CLIPLoader = NODE_CLASS_MAPPINGS[\"CLIPLoader\"]()\n",
    "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
    "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
    "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    unet = UNETLoader.load_unet(\"z-image-turbo-fp8-e4m3fn.safetensors\", \"fp8_e4m3fn_fast\")[0]\n",
    "    clip = CLIPLoader.load_clip(\"qwen_3_4b.safetensors\", type=\"lumina2\")[0]\n",
    "    vae = VAELoader.load_vae(\"ae.safetensors\")[0]\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(positive_prompt, negative_prompt=\"blurry ugly bad\", width=1024, height=1024, \n",
    "             steps=9, cfg=1.0, seed=0, sampler_name=\"euler\", scheduler=\"simple\", denoise=1.0, batch_size=1):\n",
    "    tmp_dir = \"/content/ComfyUI/output\"\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "    \n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "    \n",
    "    positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
    "    negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
    "    latent_image = EmptyLatentImage.generate(width, height, batch_size=batch_size)[0]\n",
    "    samples = KSampler.sample(unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)[0]\n",
    "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
    "    output_path = f\"{tmp_dir}/z_image_{seed}.png\"\n",
    "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(output_path)\n",
    "    return output_path, seed\n",
    "\n",
    "print(\"âœ… Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "style = {'description_width': '120px'}\n",
    "layout = widgets.Layout(width='600px')\n",
    "\n",
    "prompt_input = widgets.Textarea(\n",
    "    value='ä¸€ä½ç”·å£«å’Œä»–çš„è´µå®¾çŠ¬ç©¿ç€é…å¥—çš„æœè£…å‚åŠ ç‹—ç‹—ç§€ï¼Œå®¤å†…ç¯å…‰ï¼ŒèƒŒæ™¯ä¸­æœ‰è§‚ä¼—ã€‚',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='600px', height='80px'),\n",
    "    style=style\n",
    ")\n",
    "\n",
    "negative_input = widgets.Textarea(\n",
    "    value='blurry ugly bad',\n",
    "    description='Negative:',\n",
    "    layout=widgets.Layout(width='600px', height='60px'),\n",
    "    style=style\n",
    ")\n",
    "\n",
    "width_slider = widgets.IntSlider(value=1024, min=512, max=2048, step=64, description='Width:', style=style, layout=layout)\n",
    "height_slider = widgets.IntSlider(value=1024, min=512, max=2048, step=64, description='Height:', style=style, layout=layout)\n",
    "steps_slider = widgets.IntSlider(value=9, min=1, max=50, step=1, description='Steps:', style=style, layout=layout)\n",
    "cfg_slider = widgets.FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='CFG Scale:', style=style, layout=layout)\n",
    "seed_input = widgets.IntText(value=0, description='Seed (0=random):', style=style, layout=layout)\n",
    "\n",
    "sampler_dropdown = widgets.Dropdown(\n",
    "    options=['euler', 'euler_ancestral', 'heun', 'dpm_2', 'dpm_2_ancestral', 'lms', 'dpm_fast', 'dpm_adaptive'],\n",
    "    value='euler',\n",
    "    description='Sampler:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "scheduler_dropdown = widgets.Dropdown(\n",
    "    options=['simple', 'normal', 'karras', 'exponential', 'sgm_uniform'],\n",
    "    value='simple',\n",
    "    description='Scheduler:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "generate_btn = widgets.Button(\n",
    "    description='ğŸ¨ Generate Image',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_generate_click(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"ğŸ¨ Generating image...\")\n",
    "        try:\n",
    "            output_path, used_seed = generate(\n",
    "                positive_prompt=prompt_input.value,\n",
    "                negative_prompt=negative_input.value,\n",
    "                width=width_slider.value,\n",
    "                height=height_slider.value,\n",
    "                steps=steps_slider.value,\n",
    "                cfg=cfg_slider.value,\n",
    "                seed=seed_input.value,\n",
    "                sampler_name=sampler_dropdown.value,\n",
    "                scheduler=scheduler_dropdown.value\n",
    "            )\n",
    "            clear_output(wait=True)\n",
    "            print(f\"âœ… Image generated successfully!\\nğŸ² Seed used: {used_seed}\")\n",
    "            display(Image.open(output_path))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {str(e)}\")\n",
    "\n",
    "generate_btn.on_click(on_generate_click)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h2 style='color: #4CAF50;'>ğŸ¨ Z-Image Turbo Generator</h2>\"),\n",
    "    prompt_input,\n",
    "    negative_input,\n",
    "    widgets.HBox([width_slider, height_slider]),\n",
    "    widgets.HBox([steps_slider, cfg_slider]),\n",
    "    seed_input,\n",
    "    sampler_dropdown,\n",
    "    scheduler_dropdown,\n",
    "    generate_btn,\n",
    "    output_area\n",
    "])\n",
    "\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
