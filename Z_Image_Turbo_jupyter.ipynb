{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "accelerator": "GPU",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone -q https://github.com/comfyanonymous/ComfyUI\n",
        "%cd /content/ComfyUI\n",
        "!pip install -q -r requirements.txt\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c -q -c -x 16 -s 16 -k 1M https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors -d models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors\n",
        "!aria2c -q -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors -d models/clip -o qwen_3_4b.safetensors\n",
        "!aria2c -q -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors -d models/vae -o ae.safetensors\n",
        "\n",
        "import os, random, torch, math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "\n",
        "UNETLoader = NODE_CLASS_MAPPINGS['UNETLoader']()\n",
        "CLIPLoader = NODE_CLASS_MAPPINGS['CLIPLoader']()\n",
        "VAELoader = NODE_CLASS_MAPPINGS['VAELoader']()\n",
        "CLIPTextEncode = NODE_CLASS_MAPPINGS['CLIPTextEncode']()\n",
        "KSampler = NODE_CLASS_MAPPINGS['KSampler']()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS['VAEDecode']()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS['EmptyLatentImage']()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    unet = UNETLoader.load_unet('z-image-turbo-fp8-e4m3fn.safetensors','fp8_e4m3fn_fast')[0]\n",
        "    clip = CLIPLoader.load_clip('qwen_3_4b.safetensors', type='lumina2')[0]\n",
        "    vae = VAELoader.load_vae('ae.safetensors')[0]\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(prompt, negative, w, h, steps, cfg, seed, sampler, scheduler, denoise, batch):\n",
        "    out='/content/ComfyUI/output'\n",
        "    os.makedirs(out, exist_ok=True)\n",
        "    if seed==0:\n",
        "        seed=random.randint(0,2**64-1)\n",
        "    pos=CLIPTextEncode.encode(clip,prompt)[0]\n",
        "    neg=CLIPTextEncode.encode(clip,negative)[0]\n",
        "    latent=EmptyLatentImage.generate(w,h,batch_size=batch)[0]\n",
        "    samp=KSampler.sample(unet,seed,steps,cfg,sampler,scheduler,pos,neg,latent,denoise=denoise)[0]\n",
        "    dec=VAEDecode.decode(vae,samp)[0]\n",
        "    paths=[]\n",
        "    for i in range(batch):\n",
        "        img=Image.fromarray((dec[i].cpu().numpy()*255).astype('uint8'))\n",
        "        p=f\"{out}/zimg_{seed}_{i}.png\"\n",
        "        img.save(p)\n",
        "        paths.append(p)\n",
        "    return paths, seed\n",
        "\n",
        "def make_grid(imgs, cols):\n",
        "    rows=math.ceil(len(imgs)/cols)\n",
        "    w,h=imgs[0].size\n",
        "    g=Image.new('RGB',(cols*w,rows*h))\n",
        "    for i,im in enumerate(imgs):\n",
        "        g.paste(im,((i%cols)*w,(i//cols)*h))\n",
        "    return g\n",
        "\n",
        "import ipywidgets as w\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "PRESETS={\n",
        " 'Cinematic':'cinematic lighting, ultra realistic, shallow depth of field, film still',\n",
        " 'Portrait':'studio portrait, soft light, high detail skin texture',\n",
        " 'Anime':'anime style, clean lineart, vibrant colors',\n",
        " 'Product':'product photography, studio lighting, sharp focus, white background',\n",
        " 'NSFW Soft':'sensual pose, aesthetic nude art, soft lighting, artistic photography'\n",
        "}\n",
        "\n",
        "BASE_NEG='blurry, low quality, bad anatomy, deformed'\n",
        "NSFW_NEG='explicit sexual acts, porn, extreme fetish'\n",
        "\n",
        "preset=w.Dropdown(options=list(PRESETS.keys()),description='Preset')\n",
        "nsfw=w.Checkbox(False,description='NSFW')\n",
        "\n",
        "prompt=w.Textarea(layout=w.Layout(width='650px',height='90px'))\n",
        "neg=w.Textarea(layout=w.Layout(width='650px',height='60px'))\n",
        "\n",
        "width=w.IntSlider(1024,512,2048,64,description='Width')\n",
        "height=w.IntSlider(1024,512,2048,64,description='Height')\n",
        "steps=w.IntSlider(9,1,50,description='Steps')\n",
        "cfg=w.FloatSlider(1,0.1,10,0.1,description='CFG')\n",
        "denoise=w.FloatSlider(1,0.1,1,0.05,description='Denoise')\n",
        "batch=w.IntSlider(1,1,4,description='Batch')\n",
        "seed=w.IntText(0,description='Seed')\n",
        "\n",
        "sampler=w.Dropdown(options=['euler','euler_ancestral','dpm_fast'],description='Sampler')\n",
        "scheduler=w.Dropdown(options=['simple','karras'],description='Scheduler')\n",
        "\n",
        "grid_on=w.Checkbox(False,description='Grid')\n",
        "cols=w.IntSlider(2,2,4,description='Cols')\n",
        "\n",
        "btn=w.Button(description='GENERATE',button_style='success')\n",
        "out=w.Output()\n",
        "\n",
        "def run(b):\n",
        "    with out:\n",
        "        clear_output(wait=True)\n",
        "        p=f\"{PRESETS[preset.value]}, {prompt.value}\"\n",
        "        n=BASE_NEG\n",
        "        if not nsfw.value:\n",
        "            n+=', '+NSFW_NEG\n",
        "        paths,sd=generate(p,n,width.value,height.value,steps.value,cfg.value,seed.value,sampler.value,scheduler.value,denoise.value,batch.value)\n",
        "        imgs=[Image.open(i) for i in paths]\n",
        "        print('Seed:',sd)\n",
        "        if grid_on.value and len(imgs)>1:\n",
        "            display(make_grid(imgs,cols.value))\n",
        "        else:\n",
        "            for i in imgs: display(i)\n",
        "\n",
        "btn.on_click(run)\n",
        "\n",
        "display(w.VBox([preset,nsfw,prompt,neg,width,height,steps,cfg,denoise,batch,seed,sampler,scheduler,grid_on,cols,btn,out]))"
      ]
    }
  ]
}
